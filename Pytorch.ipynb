{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6a1000",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "077036a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e0673ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch is the core PyTorch library including tensor operations/utilities/etc\n",
    "# torch.nn is the module with neural network implementations - layers, loss functions, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad02c0",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aef52944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = nn.Embedding(1000,50)\n",
    "a = emb(torch.tensor([1,2,3]))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d482e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Embedding(num_embeddings, embedding_dim)\n",
    "# - num_embeddings refers to the \"dictionary size\" or \"vocab size\" - the number of words you're using\n",
    "# - embedding_dim refers to the size of the embedding you'll receive from using this\n",
    "\n",
    "# this function uses a lookup table that maps integer indices (what you give it) to vectors of a fixed size\n",
    "# The \"embedding table\" is initialized with random values, which are updated with backprop\n",
    "\n",
    "# every time you pass an integer to the function, it returns the vector that's currently there (it'll change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66775f",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8421229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch x torch.Size([4, 10, 300])\n",
      "unbatch x torch.Size([10, 300])\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 10\n",
    "input_features = 50\n",
    "hidden_size = 300\n",
    "batch_size = 16\n",
    "num_layers = 1\n",
    "rnn = torch.nn.RNN(input_features, hidden_size, num_layers, batch_first=True)\n",
    "batch_x = torch.randn((4, 10, 50))\n",
    "out, hidden = rnn(batch_x)\n",
    "print('batch x', out.shape)\n",
    "\n",
    "unbatch_x = torch.randn((10, 50))\n",
    "out, hidden = rnn(unbatch_x)\n",
    "print('unbatch x', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f06ee4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 required arguments - input_size and hidden_size\n",
    "# - the number of input features\n",
    "# - the number of features in the hidden state h\n",
    "\n",
    "# can also pass num_layers - 1 by default, specifies the number of recurrent layers. If >1 we're stacking RNNs\n",
    "    # so the second takes outputs of the first and computes final results\n",
    "\n",
    "# unbatched input is size (sequence length, input_size)\n",
    "    # sequence length is the number of words in the office case\n",
    "    # unbatched could be (100, 5000) for 100 words in a sequence, 5000 input_size (50-dim embedding)\n",
    "\n",
    "# batched input is size (batch_size, sequence length, input_size)\n",
    "    # must set batch_first=True when defining layer\n",
    "\n",
    "# outputs become (sequence length, D*hidden_size) and (batch_size, sequence_length, D*hidden_size)\n",
    "    # D = 2 if bidirectional else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "35ee0927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 300])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "x = torch.zeros(batch_size, sequence_length, input_features)\n",
    "out, hidden = rnn(x, h0)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial hidden state takes values (num_layers, batch_size, hidden_size)\n",
    "    # batch_first=True does not apply to hidden or cell states!\n",
    "    # if you include batch size in h0, you must include it in x\n",
    "        # you could take it out of both too if you want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72d73d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 300])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out = out[:, -1, :]\n",
    "final_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the \"final output\" is the output we get from the rnn at the last time step\n",
    "    # we get this by keeping all batch_size, using the -1 sequence_length, and all hidden_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c50b4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(100,10)\n",
    "out = linear(torch.randn(100))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f38b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 50\n",
    "hidden_size = 200\n",
    "num_layers = 1\n",
    "dict_size = 1000\n",
    "emb_size = 50\n",
    "\n",
    "# ! input_size must match emb_size\n",
    "\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dict_size, emb_size):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dict_size = dict_size\n",
    "        self.emb_size = emb_size\n",
    "        self.embedding = nn.Embedding(dict_size, emb_size)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 21)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        print(x.shape)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        print(x.shape, h0.shape)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = RNNClassifier(input_size, hidden_size, num_layers, dict_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52de3e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 50, 50])\n",
      "torch.Size([10, 50, 50]) torch.Size([1, 10, 200])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "x = torch.zeros(batch_size, input_size).int()\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c03cc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854],\n",
       "        [ 0.3445,  0.2529, -0.0758, -0.1560, -0.1792, -0.2978,  0.0266,  0.2951,\n",
       "          0.1216,  0.2107, -0.1691, -0.1297,  0.0762, -0.3954, -0.2504,  0.0926,\n",
       "         -0.1776,  0.3120, -0.1057,  0.0903,  0.2854]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0a0c718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "522899c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8621, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "loss(a, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d87ad0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1643)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(21)\n",
    "a[torch.argmax(a)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb34c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979e19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfg",
   "language": "python",
   "name": "lfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
